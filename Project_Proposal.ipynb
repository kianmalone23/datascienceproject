{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Expansion rate of the Universe\n",
    "-  Kian Malone, u1008257, kianjamesmalone@gmail.com\n",
    "- Nicky Keefer, u0633469, n.keefer@utah.edu\n",
    "- Joey Diconza, u0766017, joey@diconza.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Motivation\n",
    "We are interested in verifying the current scientific view of our universe, while simultaneously showing the power of data science. Two of our team members are physics majors with the third being a math major. We are a curious bunch and have thankfully had opportunities to see scientific processes that yield unimaginable truths about reality. <br/>\n",
    "<br/>\n",
    "By the power of Data Science and Astrophysical observations, we can show others something deeply revealing about the grand structure of the Universe.<br/>\n",
    "<br/>\n",
    "\n",
    "## Project Objectives \n",
    "Is the Universe actually accelerating in its expansion? This question is made of smaller questions like: Are the distances between all objects growing? Is the increase in velocity proportional to the increase in distance? Does our calculation of the Hubble constant get us close to the the gravitational wave calculation of the Hubble constant? Are the objects, that are further and further away, more and more redshifted? By answering these questions we will in fact re-postulate the idea behind the accelerating expansion of the Universe and provide support for the Big Bang model.<br/>\n",
    "<br/>\n",
    "The benefits are that we can arrive at the same conclusion of professional scientists around the world but by a method completely different than the one that was used to prove its original validity.  We can show that by different methods of measuring reality we can arrive at a conclusion that is invariant of the method used to get there. Therefore providing our best guess/understanding about some aspect of nature. By verifying one of the most unimaginable truths about reality we are proving that a lot of data and a little knowledge can take you (literally) to the edge of the Universe and back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will obtain our data from the Sloan Digital Sky Survey, or SDSS. They provide a multi-Terabyte dataset of optical and infrared spectra on nearby stars and galaxies. The University of Utah has contributed to the project!\n",
    "\n",
    "<https://www.sdss.org/dr15/data_access/>\n",
    "\n",
    "All SDSS data is available to the public. SDSS provides all data free of charge. \"We would like to show you the beauty of the universe, and share with you our excitement as we build the largest map in the history of the world.\" (<http://skyserver.sdss.org/dr15/en/home.aspx>)\n",
    "\n",
    "Data should include:\n",
    "\n",
    "- Redshift values for nearby stars and galaxies\n",
    "\n",
    "- Optical and Infrared spectra data\n",
    "\n",
    "- More values as determined necessary during the execution of the project\n",
    "\n",
    "## Ethical Considerations\n",
    "\n",
    "This project should not run into any major ethical problems. We aren't modifying any genetic code or manipulating human behavior. We're just looking at the Universe around us!\n",
    "\n",
    "Perhaps, while running our analysis, we will discover intelligent extraterrestrial life. That would probably lead to several ethical dillemas. We aren't too worried about that, though.\n",
    "\n",
    "## Data Processing\n",
    "\n",
    "We plan on learning some basics of SQL in order to obtain raw data and get it into a .csv format that is readable and cleanable in Python/Pandas:\n",
    "\n",
    "<http://skyserver.sdss.org/dr15/en/help/docs/sql_help.aspx>\n",
    "\n",
    "We will potentially need to combine several data sets to obtain all of the information we need to complete the project.\n",
    "\n",
    "The data will be raw from telescope readings, and will need to be heavily cleaned and processed into a nice Pandas dataframe for analysis.\n",
    "\n",
    "Since this is physics data, many unit conversions on the data will probably be necessary as well.\n",
    "\n",
    "## Exploratory Analysis\n",
    "\n",
    "Once clean data is obtained, we plan to present the following exploratory analysis:\n",
    "\n",
    "- A quick overall data summary with Quartiles, Standard deviations, etc... for each variable in the set, accompanied with interpretation.\n",
    "\n",
    "- Experimental mean value for expansion of the Universe (in kilometers per second per megaparsec).\n",
    "\n",
    "- 95% Confidence Interval for the mean value of the rate of expansion of the Universe.\n",
    "\n",
    "- Correlation matrix with scatter plots for appropriate variables, with interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Methodology\n",
    "To analyze this data we will be focusing on finding the slope of the linear regression of distance vs speed of various interstellar objects.<br/>\n",
    "<br/>\n",
    "Our main concern will be accounting for extinction among farther away objects, we will have to do correct this to get correct data, but it will contribute to our error propogation, thus it also may be benificial to exclude objects with suspected extinction if we have a large enough sample size without them.<br/> \n",
    "<br/> \n",
    "The slope of this linear regression should give us an estimate for the Hubble parameter in 1/seconds, giving us a rough estimate of the age of the universe and its expansion rate. If time allows we can also use this to estimate the end state of our universe. <br/>\n",
    "<br/>\n",
    "The final idea for analyzing is after we have acheived some sort of basic estimate we can use a t-test to check the signifigance of this value and hopefully use it as evidence to support the expanding universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Schedule\n",
    "\n",
    "- March 3-9\n",
    "    -  Start accessing data, and storing the rough data we need into CSV's\n",
    "- March 10-16\n",
    "    -  Start sorting and cleaning data, specifiying what are the important columns and data needed\n",
    "- March 17-23\n",
    "    -  figure out method of which to analyze the data to get a rough estimate on the hubble parameter.\n",
    "- March 24-30\n",
    "    -  Make sure all is ready for Project Milestone due the 31st. Check data and show what equations we will use and future ideas for analyzing.\n",
    "- March 31-April 6\n",
    "    -  Start writing final code to do calculations and check with proffesor if necessary\n",
    "- April 7-13\n",
    "    -  Start building screen-cast, as well as cleaning up notebook file with all the work, start working on presentation plan\n",
    "- April 14-21\n",
    "    -  Have analysis part fully done and finish up the screen cast and presentation to be ready for the last two lectures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
