{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Milestone**\n",
    "\n",
    "\n",
    "Names: Nicky Keefer, Joey DiConza, Kian Malone\n",
    "\n",
    "\n",
    "UID: u0633469, u0766017, u1008257\n",
    "\n",
    "\n",
    "emails: ntkeefer@gmail.com, joey@diconza.com, kianjamesmalone@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**\n",
    "\n",
    "We acquired our raw data from the SLOAN DIGITAL SKY SURVEY (SDSS). At the SDSS website, they have a built-in [SQL Query Request Tool](http://skyserver.sdss.org/dr15/en/tools/search/sql.aspx). While this did make our life much easier, there were basic query limits of 500,000 rows and 10 minute time-out, thus we had to learn some basics of SQL and query optimization in order to sumbit the following request to the SDSS database:\n",
    "\n",
    "SELECT\n",
    "   s.class, \n",
    "   s.z, \n",
    "   s.zErr,\n",
    "   p.modelMag_g, \n",
    "   p.modelMagErr_g,\n",
    "   p.extinction_g,\n",
    "   p.modelMag_r,\n",
    "   p.modelMagErr_r,\n",
    "   p.extinction_r\n",
    "    \n",
    "FROM PhotoTag AS p, JOIN SpecObj AS s ON s.bestobjid = p.objID\n",
    "\n",
    "WHERE \n",
    "    s.zWarning=0\n",
    "    AND (s.class = 'QSO' OR s.class = 'GALAXY')\n",
    "    AND (p.htmID*37 & 0x000000000000FFFF) < (650 * 0.5)\n",
    "\n",
    "\n",
    "\n",
    "What this did was select a random sample of .005% of the SDSS data's on  galaxies and quasars (our final n = 14,091). We grabbed the data columns representing the apparent magnitude in the green and red band,as well as the redshift for these objects, and all of their associated errors. Along with these we also pulled the extinction in the red band just in case we have a large deviation from the expected result, we can add extra correction factors to see if anything changes. Due to the sampling being random, and out sample size is large, we can infer better estimates about the Universe as a whole from this data set. In turn, satisfying our intitial goal for the project.\n",
    "\n",
    "While variables from two seperate SDSS tables were needed, we were able to join everything into a single table using the JOIN function and a common object id to match up the data before we Queried. We also made certain that no entries have \"NA\" values in any column using zwarning=0, a binary column in the SpecObj table that makes sure we are pulling data that has no issues or missing values throughout, this matches up with objects that are also clean in the other table, helping us cut down on our data clean up even before we pulled it!\n",
    "\n",
    "After we obtained the raw data, we had to clean the numbers in the following ways. We had to convert our almost all columns to a float, since they all came in as strings. We also renamed each column to make it easier to work with. Once we were happy with this, we were ready to start creating new columns/data frames for our initial analysis.\n",
    "\n",
    "\n",
    "We included the inital pulled data in the file **finalroughdata.csv\"** and the final,cleaned data in the file **\"finalcleandata.csv\"** as well as the data cleaning process in the note book file **\"Data_Cleaning.ipynb\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Peer Review Advice**\n",
    "\n",
    "During the Peer Review, the other group was concerned with the difficulty and scope of our initial goals. Our peers skepticism was due to our uncertaintity in, how easy or hard our goals would be. Between then and now we have come to the conclusion that the project will definitely be feasible. \n",
    "\n",
    "Another fairly large concern was, how we would deal with the light extinction. We resolved this by pulling the extinction values for both of our green and red band magnitudes. We can then add this correction value when solving for its Absolute magnitude, hopefully leading us to a more clear correlation of red vs blue galaxies. \n",
    "\n",
    "The other group also wanted us to consider which possible time frames would yield the result we were shooting for. We alleviated this by sampling randomly and at large-ish *n*.\n",
    "\n",
    "Our peers were curious how we would go about visualizing the data and if we would be able to do any ML application. We decided that a linear regression was perfect for re-discovering the Hubble Parameter and verifying our initial goal for the project. Secondly, we came up with a phase II that includes ML classification of our different data points (aka galaxies and quasars).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis**\n",
    "\n",
    "Since we know overall what the relationships are for our data, it was hard to check for other correlations and different ideas to produce, so for our main EDA we stuck with analyzing our 5 number summary, which is included in the **\"EDA.ipynb\"** file.\n",
    "\n",
    "\n",
    "Overall our summary of the data came out how we had hoped. While there are large outliers in the data for every column, the standard deviations,  medians, and means are all a good representation of the data due to the large amount that we extracted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sketches of Analysis Plan**\n",
    "\n",
    "*Part 1*\n",
    "\n",
    "Our main idea behind this project is broken up into two main parts. The first being trying to reproduce the hubble constant by constructing a graph of distance vs velocity. For velocity it is a very simple equation that we can use $$v=c*\\frac{(z+1)^2-1}{(z+1)^2+1}$$ where c is the speed of light and z is redshift, this approximation can be used because we are assuming that overall we will not have any objects at such a high redshift that we must include the relativistic correction. We will go back and asses this approximation if necessary.\n",
    "\n",
    "\n",
    "To calculate the distance we are using the flux equation $$F=\\frac{L}{4\\pi*d^2}$$ where F is the Flux of the star in Watts per meter, L is Luminosity, and d is the distance to the star. \n",
    "\n",
    "\n",
    "We then rearrange to solve for distance and get $$d=\\sqrt{\\frac{L}{4\\pi*F}}$$ \n",
    "For this analysis a large assumption we are going to make is assume Galaxies and QSO's can be represented as a standard candle when sampled on such a large scale. We will assume two seperate Lumonisties for QSO and Galaxies in watts,5e36 and 2e40 respectively.\n",
    "\n",
    "To find Flux we will be using the apparent magnitude in the red band since it captures the most data. We will be using the equation $$F=F_{sun}*10^{0.4(m_{sun}-m)}$$\n",
    "Where the m represents the apparent magintude in the red band. Since both the apparent magnitude and flux of the sun are know, we just plug in our magnitude from SDSS and find our flux, then using that to find distance we now have out data to create the distance vs velocity graph. Once we have done this we will take a linear regression and calculate the slope of the line, this will be our estimate for the hubble parameter. Depending on our outcome and regression $R^2$ value we can look at extinction or our assumtion on velocity and luminosities.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part 2*\n",
    "\n",
    "\n",
    "Once we have our Hubble constant $(H_0)$ estimate we can move on to the second part of our project. Using machine learing to reproduce the categorial grouping of Red vs Blue galaxies. To do this we will use a graph of Absolute Magnitude vs (g-r), where (g-r) is the differenct between the green and red apparent magnitude. The importance of (g-r) is that the high values represent redder objects and lower values represent bluer objects.\n",
    "\n",
    "\n",
    "Apparent magnitude is brightness of the object at a standard distance 10 parsecs or around 31 light years. To calculate this value from our apparent magnitude, we will be using just the red band again due to its higher sensitivity and using the equation $$M_{absolute}=m_{apparent}-5\\log_{10}{(\\frac{c*z}{H_0})}+5-A_r$$\n",
    "where $A_r$ is the extinction value and $m_{apparent}$ is the red band magnitude. Once we have these we can create a scatter plot and use a support vector machine to create a kernal to classify galaxies as red vs blue. If all goes smoothly, we may attempt to use the actual value of $H_0$ as well as our derived one from part 1. \n",
    "\n",
    "Overall we believe this project is within our skill level while still having to overcome many challenges along the way. We are excited to progress and see the results, as well as use our results to show some interesting data about the universe we live in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
